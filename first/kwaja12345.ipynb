{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom glob import glob\nimport matplotlib.pyplot as plt\nimport random\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns\nimport zlib\nimport itertools\nimport sklearn\nimport itertools\nimport scipy\nimport skimage\nfrom skimage.transform import resize\nimport csv\nfrom tqdm import tqdm\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split,learning_curve,KFold,cross_val_score,StratifiedKFold\nfrom sklearn.utils import class_weight\nfrom sklearn.metrics import confusion_matrix\nimport keras\nfrom keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Lambda,MaxPool2D, BatchNormalization\nfrom keras.utils import np_utils\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import models, layers, optimizers\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.utils import class_weight\nfrom keras.models import Sequential, model_from_json\nfrom keras.layers import Activation,Dense, Dropout, Flatten, Conv2D,MaxPool2D,MaxPooling2D,AvgPool2D, BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nfrom keras import backend as K\nfrom keras.applications.vgg16 import VGG16\nfrom keras.models import Model\nfrom keras.applications.inception_v3 import InceptionV3\nfrom imblearn.over_sampling import RandomOverSampler","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:44:33.514495Z","iopub.execute_input":"2021-12-19T09:44:33.514876Z","iopub.status.idle":"2021-12-19T09:44:39.601752Z","shell.execute_reply.started":"2021-12-19T09:44:33.514789Z","shell.execute_reply":"2021-12-19T09:44:39.600998Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"imageSize=227\ntrain_dir = \"../input/kermany2018/oct2017/OCT2017 /train/\"\ntest_dir = \"../input/kermany2018/oct2017/OCT2017 /test/\"\n# ['DME', 'CNV', 'NORMAL', '.DS_Store', 'DRUSEN']\nfrom tqdm import tqdm\ndef get_data(folder):\n    \"\"\"\n        Load the data and labels from the given folder.\n    \"\"\"\n    X = []\n    y = []\n    for folderName in os.listdir(folder):\n        if not folderName.startswith('.'):\n            if folderName in ['NORMAL']:\n                label = 0\n            elif folderName in ['CNV']:\n                label = 1\n            elif folderName in ['DME']:\n                label = 2\n            elif folderName in ['DRUSEN']:\n                label = 3\n            else:\n                label = 4\n            for image_filename in tqdm(os.listdir(folder + folderName)):\n                img_file = cv2.imread(folder + folderName + '/' + image_filename)\n                if img_file is not None:\n                    img_file = skimage.transform.resize(img_file, (imageSize, imageSize, 3))\n                    img_arr = np.asarray(img_file)\n                    X.append(img_arr)\n                    y.append(label)\n    X = np.asarray(X)\n    y = np.asarray(y)\n    return X,y\n#X_train, y_train = get_data(train_dir) # Un-comment to use full dataset: Step 1 of 2\nX_test, y_test= get_data(test_dir)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:47:21.704172Z","iopub.execute_input":"2021-12-19T09:47:21.704442Z","iopub.status.idle":"2021-12-19T09:48:09.434110Z","shell.execute_reply.started":"2021-12-19T09:47:21.704411Z","shell.execute_reply":"2021-12-19T09:48:09.433357Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_test, y_test, test_size=0.2) \n# Re-comment touse full dataset\n# Encode labels to hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\nfrom keras.utils.np_utils import to_categorical\ny_trainHot = to_categorical(y_train, num_classes = 4)\ny_testHot = to_categorical(y_test, num_classes = 4)\nprint(\"The size of X_train is: {}\".format(X_train.shape))\nprint(\"The size of y_train is: {}\".format(y_train.shape))\nprint(\"The size of X_test is: {}\".format(X_test.shape))\nprint(\"The size of y_test is: {}\".format(y_test.shape))\nX_train = X_train.reshape(X_train.shape[0], 227, 227, 3)\nX_test = X_test.reshape(X_test.shape[0], 227, 227, 3)\nX_train=X_train/255.0\nX_test=X_test/255.0\n","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:48:14.546222Z","iopub.execute_input":"2021-12-19T09:48:14.546520Z","iopub.status.idle":"2021-12-19T09:48:15.251343Z","shell.execute_reply.started":"2021-12-19T09:48:14.546492Z","shell.execute_reply":"2021-12-19T09:48:15.250603Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# (3) Create a sequential model\nmodel = Sequential()\n\n# 1st Convolutional Layer\nmodel.add(Conv2D(filters=96, input_shape=(227,227,3), kernel_size=(11,11),\\\n strides=(4,4), padding='valid'))\nmodel.add(Activation('relu'))\n# Pooling \nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n# Batch Normalisation before passing it to the next layer\nmodel.add(BatchNormalization())\n\n# 2nd Convolutional Layer\nmodel.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\nmodel.add(Activation('relu'))\n# Pooling\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# 3rd Convolutional Layer\nmodel.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\nmodel.add(Activation('relu'))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# 4th Convolutional Layer\nmodel.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\nmodel.add(Activation('relu'))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# 5th Convolutional Layer\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\nmodel.add(Activation('relu'))\n# Pooling\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# Passing it to a dense layer\nmodel.add(Flatten())\n# 1st Dense Layer\nmodel.add(Dense(4096, input_shape=(224*224*3,)))\nmodel.add(Activation('relu'))\n# Add Dropout to prevent overfitting\nmodel.add(Dropout(0.4))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# 2nd Dense Layer\nmodel.add(Dense(4096))\nmodel.add(Activation('relu'))\n# Add Dropout\nmodel.add(Dropout(0.4))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# 3rd Dense Layer\nmodel.add(Dense(1000))\nmodel.add(Activation('relu'))\n# Add Dropout\nmodel.add(Dropout(0.4))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# Output Layer\nmodel.add(Dense(17))\nmodel.add(Activation('softmax'))\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:48:28.025159Z","iopub.execute_input":"2021-12-19T09:48:28.025697Z","iopub.status.idle":"2021-12-19T09:48:28.237103Z","shell.execute_reply.started":"2021-12-19T09:48:28.025658Z","shell.execute_reply":"2021-12-19T09:48:28.236428Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='sparse_categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:48:44.207605Z","iopub.execute_input":"2021-12-19T09:48:44.207945Z","iopub.status.idle":"2021-12-19T09:48:44.243974Z","shell.execute_reply.started":"2021-12-19T09:48:44.207905Z","shell.execute_reply":"2021-12-19T09:48:44.243268Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"datagen=ImageDataGenerator(featurewise_center=False,\nsamplewise_center=False,\nfeaturewise_std_normalization=False,\nzca_whitening=False,\nrotation_range=1,\nzoom_range=0.1,\nwidth_shift_range=0.1,\nheight_shift_range=0.1,\nhorizontal_flip=False,\nvertical_flip=False)\ndatagen.fit(X_train)\nhist=model.fit_generator(datagen.flow(X_train,y_train,batch_size=10),epochs=50,verbose=1,validation_data=(X_test,y_test))\nscore=model.evaluate(X_test,y_test)\nprint('test loss:',score[0])\nprint('test accuracy:',score[1])","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:49:01.557593Z","iopub.execute_input":"2021-12-19T09:49:01.558520Z","iopub.status.idle":"2021-12-19T09:55:45.148703Z","shell.execute_reply.started":"2021-12-19T09:49:01.558475Z","shell.execute_reply":"2021-12-19T09:55:45.147978Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"val_acc=hist.history['val_accuracy']\nacc=hist.history['accuracy']\nval_loss=hist.history['val_loss']\nloss=hist.history['loss']","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:55:54.705981Z","iopub.execute_input":"2021-12-19T09:55:54.706240Z","iopub.status.idle":"2021-12-19T09:55:54.711927Z","shell.execute_reply.started":"2021-12-19T09:55:54.706213Z","shell.execute_reply":"2021-12-19T09:55:54.711232Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"fig=plt.figure(figsize=(14,6))\nplt.plot(np.arange(len(val_loss)),val_loss,label='val_loss')\nplt.plot(np.arange(len(loss)),loss,label='loss')\nplt.ylim(0.1,1.5)\nplt.xlabel(\"Eppochs\")\nplt.ylabel(\"loss\")\nplt.legend()\nsns.despine(left=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:55:59.149990Z","iopub.execute_input":"2021-12-19T09:55:59.150267Z","iopub.status.idle":"2021-12-19T09:55:59.398036Z","shell.execute_reply.started":"2021-12-19T09:55:59.150235Z","shell.execute_reply":"2021-12-19T09:55:59.397365Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"fig=plt.figure(figsize=(14,6))\nplt.plot(np.arange(len(val_acc)),val_acc,label='val_accuracy')\nplt.plot(np.arange(len(acc)),acc,label='accuracy')\nplt.ylim(0.1,1.5)\nplt.xlabel(\"Eppochs\")\nplt.ylabel(\"accuracy\")\nplt.legend()\nsns.despine(left=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:56:05.730263Z","iopub.execute_input":"2021-12-19T09:56:05.730941Z","iopub.status.idle":"2021-12-19T09:56:05.953294Z","shell.execute_reply.started":"2021-12-19T09:56:05.730896Z","shell.execute_reply":"2021-12-19T09:56:05.952659Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"pred=model.predict(X_test,batch_size=10)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:58:33.944269Z","iopub.execute_input":"2021-12-19T09:58:33.944770Z","iopub.status.idle":"2021-12-19T09:58:34.310366Z","shell.execute_reply.started":"2021-12-19T09:58:33.944732Z","shell.execute_reply":"2021-12-19T09:58:34.309588Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"prd=[]\nfor i in range(len(pred)):\n    prd.append(np.argmax(pred.round()[i]))\nconf=pd.DataFrame(confusion_matrix(y_test,prd))","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:58:36.427737Z","iopub.execute_input":"2021-12-19T09:58:36.428278Z","iopub.status.idle":"2021-12-19T09:58:36.436909Z","shell.execute_reply.started":"2021-12-19T09:58:36.428238Z","shell.execute_reply":"2021-12-19T09:58:36.436001Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"print('\\nConfusion Matrix ')\nconf","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:58:44.665625Z","iopub.execute_input":"2021-12-19T09:58:44.666150Z","iopub.status.idle":"2021-12-19T09:58:44.675957Z","shell.execute_reply.started":"2021-12-19T09:58:44.666111Z","shell.execute_reply":"2021-12-19T09:58:44.675157Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}